{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vitoraugusto1993/Coursera-courses/blob/main/LLM/Hugging%20Face/Fine%20Tuning/IMDB_reviews_PEFT_techniques_comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jycxAE8Xfum"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade pandas numpy transformers datasets evaluate torch accelerate>=0.26.0 psutil bitsandbytes mlflow==3.1.1 mlflow-skinny==3.1.1 nltk pandas==2.2.2 numpy==2.0 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1M0DIh1zklly",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import mlflow\n",
        "import evaluate\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import transformers\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "from transformers.integrations import MLflowCallback\n",
        "import datasets\n",
        "from datasets import Dataset\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import random # Random module for generating random numbers and selections\n",
        "import nltk\n",
        "nltk.download('wordnet') # NLTK's WordNet corpus for finding synonyms\n",
        "from nltk.corpus import wordnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "II7ZRWpwk8mK"
      },
      "outputs": [],
      "source": [
        "get_ipython().system_raw(\"mlflow ui --port 5000 &\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxQQ68DXlEDD",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install pyngrok --quiet\n",
        "\n",
        "from pyngrok import ngrok\n",
        "from getpass import getpass\n",
        "\n",
        "# Terminate open tunnels if exist\n",
        "# ngrok.kill()\n",
        "\n",
        "# Setting the authtoken (optional)\n",
        "# Get your authtoken from https://dashboard.ngrok.com/auth\n",
        "NGROK_AUTH_TOKEN = getpass('Enter the ngrok authtoken: ')\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# O pen an HTTPs tunnel on port 5000 for http://localhost:5000\n",
        "# 334eXKKnAypyTHCxzcxMRyrzuD7_7pq3ycoPsKoKbARcxuV8C\n",
        "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
        "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiVRvV4BmCB1"
      },
      "source": [
        "## Step 1: Import data set\n",
        "\n",
        "Import dataset from Hugging Face Hub. This Dataset contains thousands of reviews from IMDB about movies, classified as Negative (0) and Positive (1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQYVRnIxmJIy",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "data = datasets.load_dataset('imdb')\n",
        "dataset = data['train'].to_pandas()\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuar7v2QmvpB"
      },
      "source": [
        "##### Step 2: Clean the text\n",
        "\n",
        "This step is cleaning the raw text data to remove unnecessary characters, such as URLs, special symbols, or HTML tags, and to normalize the text by converting it to lowercase.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McsRdKK_mSYe",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Function to clean the text\n",
        "def clean_text(text):\n",
        "    text = str(text).lower() # Convert all text to lowercase for uniformity\n",
        "    text = re.sub(r'http\\S+', '', text) # Remove URLs from the text\n",
        "    text = re.sub(r'<.*?>', '', text) # Remove any HTML tags from the text\n",
        "    # text = re.sub(r'[^\\w\\s]', '', text) # Remove punctuation, keep only words and spaces\n",
        "    return text # Return the cleaned text\n",
        "\n",
        "# Assume `data` is a pandas DataFrame with a column named 'text'\n",
        "# Apply the cleaning function to each row of the 'text' column\n",
        "dataset['cleaned_text'] = dataset['text'].apply(clean_text)\n",
        "\n",
        "# Remove un-necessary columns\n",
        "dataset = dataset.drop(['text'], axis=1)\n",
        "\n",
        "# Print the first 5 rows of the cleaned text to verify the cleaning process\n",
        "print(dataset.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLifozbAnYqg"
      },
      "source": [
        "## Step 3: Handle missing data\n",
        "\n",
        "Check for empty entries in the column 'cleaned_text'. If there are missing data, we should delete the entire rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GudiP1-xnTmX",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Print the count of missing values for each column\n",
        "print(dataset.isnull().sum())\n",
        "print('--------------------')\n",
        "\n",
        "# Remove rows with missing data in the 'text' column\n",
        "dataset = dataset.dropna()\n",
        "\n",
        "# Confirmation of no missing data in the dataset\n",
        "print(dataset.isnull().sum())\n",
        "print('--------------------')\n",
        "\n",
        "# Print the count of entries in the dataset\n",
        "print(dataset.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMUBZ9oyncqf",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "dataset.groupby('label')['cleaned_text'].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHrpBc31m6Kv",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "dataset['label'].hist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0lZG2MXnsP5"
      },
      "source": [
        "## Step 4: Tokenization\n",
        "\n",
        "After cleaning the text, we tokenize it. Tokenization splits the text into individual words or subwords that can be used by the model. We will use the DistilBERT tokenizer to ensure compatibility with the pretrained model you are fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCQ2_eAqnj4R",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "dataset_ds = Dataset.from_pandas(dataset)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['cleaned_text'], truncation=True)\n",
        "\n",
        "tokenized_dataset = dataset_ds.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgaO21ndoNVK",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "tokenized_dataset = tokenized_dataset.remove_columns(['cleaned_text'])\n",
        "tokenized_dataset = tokenized_dataset.rename_column('label', 'labels')\n",
        "tokenized_dataset.set_format(\"torch\")\n",
        "tokenized_dataset.column_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZ8zk56OqB-L"
      },
      "source": [
        "## Step 5: Structure the data for fine-tuning\n",
        "\n",
        "You can fine-tune your model once the dataset is cleaned and tokenized. The next step is structuring the data for fine-tuning.\n",
        "\n",
        "First we will split our dataset into three separate datasets: training, validation and test. For this case, we will use 70% of the whole dataset to train de model, 15% to validade and 15% to test. Then, we need to convert our pandas dataframes back to Datasets objects. With our dataset splited and converted, we have to remove an extra column that these steps added ('__index_level_0__')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHH4sV40pgJb"
      },
      "outputs": [],
      "source": [
        "tokenized_df = tokenized_dataset.to_pandas()\n",
        "\n",
        "train_df, val_test_df = train_test_split(\n",
        "    tokenized_df, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "val_df, test_df = train_test_split(\n",
        "    val_test_df, test_size=0.5, random_state=42\n",
        ")\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "train_dataset = train_dataset.remove_columns(['__index_level_0__'])\n",
        "val_dataset = val_dataset.remove_columns(['__index_level_0__'])\n",
        "test_dataset = test_dataset.remove_columns(['__index_level_0__'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNbWoadqqM2d"
      },
      "source": [
        "When we load a dataset using the load_dataset from library datasets, they are presented as a DatasetDict object. Sometimes the dataset is already splited into train, validation and test. So, in the next step, we will create a DatasetDict object just like the ones we get when me use load_data function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZpME_v7qKSG",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "tweet_dataset = DatasetDict({\"train\": train_dataset, \"val\": val_dataset, \"test\":test_dataset})\n",
        "tweet_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0JXIVeRqjmk"
      },
      "source": [
        "Now we can create the dataloaders we will use to iterate over batches. We can easily define them as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBY1ZxCxqO77",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Create DataLoader objects\n",
        "train_dataloader = DataLoader(tweet_dataset[\"train\"], batch_size=16, collate_fn=data_collator, shuffle=True)\n",
        "val_dataloader = DataLoader(tweet_dataset[\"val\"], batch_size=16, collate_fn=data_collator)\n",
        "test_dataloader = DataLoader(tweet_dataset[\"test\"], batch_size=16, collate_fn=data_collator)\n",
        "\n",
        "print(\"Training, validation, and test sets are prepared with attention masks!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrvC4v12qnnq"
      },
      "source": [
        "To quickly check there is no mistake in the data processing, we can inspect a batch like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ADzlr89qhyr",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "for batch in train_dataloader:\n",
        "    break\n",
        "{k: v.shape for k, v in batch.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btTa8ykJqy95"
      },
      "source": [
        "## Step 6: Create the model\n",
        "\n",
        "### PEFT (trainning only the last layer before classification head)\n",
        "\n",
        "Now that we're completely finished with data preprocessing, let's turn to the model. We instantiate it by referencing the pretrained model we want to fine tune. In this case e are using a base BERT model. As we want to perform PEFT (parameter efficient fine-tuning), we need to follow somes steps before training. First, we freeze all model layers, except the last one, which is the classification head layer. Optionally, we can unfreeze a few layers before the classification head if you judge necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTKia7gTqq4C",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from transformers import DistilBertForSequenceClassification\n",
        "\n",
        "DistilBertModel = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
        "model = DistilBertModel\n",
        "\n",
        "# Step 1: Freeze all layers except the last one (classification head)\n",
        "for param in model.base_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# If you'd like to fine-tune additional layers (e.g., the last 2 layers), you can unfreeze those layers as well\n",
        "for param in model.base_model.transformer.layer[-2:].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "trainable_params = 0\n",
        "all_params = 0\n",
        "for _, param in model.named_parameters():\n",
        "    all_params += param.numel()\n",
        "    if param.requires_grad:\n",
        "        trainable_params += param.numel()\n",
        "\n",
        "# Print the results\n",
        "print(f\"Trainable parameters: {trainable_params} || Total parameters: {all_params} || Trainable percentage: {100 * trainable_params / all_params:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LoRA"
      ],
      "metadata": {
        "id": "da0nmamcwKvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "        r=32,\n",
        "        lora_alpha=64,\n",
        "        target_modules=['v_lin','k_lin','q_lin'],\n",
        "        lora_dropout=0.1,\n",
        "        bias='none',\n",
        "        task_type=\"SEQ_CLS\" # Specify the task type\n",
        "    )\n",
        "\n",
        "lora_model = get_peft_model(DistilBertModel, lora_config)\n",
        "lora_model.print_trainable_parameters() # To see the number of trainable parameters"
      ],
      "metadata": {
        "id": "DAk1zovgwiCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### QLoRA"
      ],
      "metadata": {
        "id": "t8a-JVBOyE88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bitsandbytes as bnb\n",
        "from transformers import BitsAndBytesConfig\n",
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "# 1. Define the quantization configuration\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\", # NormalFloat 4-bit quantization\n",
        "    bnb_4bit_use_double_quant=True, # Nested quantization\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16, # Compute type for faster operations\n",
        ")\n",
        "\n",
        "# 2. Load the base model with quantization\n",
        "# Ensure you have device_map='auto' for efficient memory usage across devices\n",
        "QDistilBertModel = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\",\n",
        "                                                            num_labels=2,\n",
        "                                                            device_map=\"auto\",\n",
        "                                                            torch_dtype=torch.bfloat16, # Use bfloat16 for the model's data type\n",
        "                                                            )\n",
        "\n",
        "# Prepare model for k-bit training (important for QLoRA)\n",
        "QDistilBertModel = prepare_model_for_kbit_training(QDistilBertModel)\n",
        "\n",
        "qlora_config = LoraConfig(r=32,\n",
        "                          lora_alpha=64,\n",
        "                          target_modules=['v_lin','k_lin','q_lin'],\n",
        "                          lora_dropout=0.1,\n",
        "                          bias='none',\n",
        "                          task_type=\"SEQ_CLS\" # Specify the task type\n",
        "                          )\n",
        "\n",
        "qlora_model = get_peft_model(QDistilBertModel, qlora_config)\n",
        "qlora_model.print_trainable_parameters() # To see the number of trainable parameters"
      ],
      "metadata": {
        "id": "6436ZPkyyHIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS1h-IvFrpUB"
      },
      "source": [
        "## Step 7: Training loop configuration\n",
        "\n",
        "### PEFT\n",
        "\n",
        "Before setting the training loop, we need to specificate two important things: the optimizer and a learning rate scheduler. Since we are trying to replicate what the Trainer was doing by hand, we will use the same defaults. The optimizer used by the Trainer is Adafactor, wich is the same as Adam, but with a twist for weight decay regularization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AeZ67EdkriTU"
      },
      "outputs": [],
      "source": [
        "from transformers import Adafactor\n",
        "\n",
        "optimizer = Adafactor(model.parameters(), lr=2e-5, relative_step=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onmapceNtepg"
      },
      "source": [
        "Finally, the learning rate scheduler used by default is just a linear decay from the maximum value to 0. To properly define it, we need to know the number of training steps we will take, wich is the number of epochs we want to run multiplied by the number of training batches (which is the length of our training dataloader). The Trainer uses three epochs by default, so we will follow that:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tX6-Wr7UsGbu",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from transformers import get_scheduler\n",
        "\n",
        "num_epochs = 5\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "print(num_training_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO3r_zhMtm-p"
      },
      "source": [
        "We are now ready to train\" To get some sense of when training will be finished, we add a progress bar over our number of training steps, using tqdm library:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWEBOtaOrg1Q",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch.to(device)"
      ],
      "metadata": {
        "id": "HXr-V6GAevzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**batch)\n",
        "print(outputs.loss, outputs.logits.shape)"
      ],
      "metadata": {
        "id": "zMlmBBNs0f0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_saBzcTOsOmv",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "import mlflow\n",
        "import evaluate\n",
        "\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "precision = evaluate.load(\"precision\")\n",
        "recall = evaluate.load(\"recall\")\n",
        "f1 = evaluate.load(\"f1\")\n",
        "\n",
        "metrics = evaluate.combine([\"precision\",\"f1\",\"recall\"])\n",
        "\n",
        "mlflow.set_experiment(\"Simple_PEFT_IMDB\")\n",
        "mlflow.pytorch.autolog()\n",
        "step = 1\n",
        "\n",
        "with mlflow.start_run(log_system_metrics=True) as run:\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch in train_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        step +=1\n",
        "        mlflow.log_metric(\"train_loss\", loss.item(), step=step)\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "\n",
        "    model.eval()\n",
        "    for batch in val_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "        metrics.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "    results = metrics.compute(average=\"weighted\")\n",
        "    ml_metrics = {\"eval_precision\": results[\"precision\"],\n",
        "                  \"eval_recall\": results[\"recall\"],\n",
        "                  \"eval_f1\": results[\"f1\"]}\n",
        "    mlflow.log_metrics(ml_metrics, step=epoch)\n",
        "    print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX43rTGMCTGp"
      },
      "source": [
        "### LoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8UHFW8iC3hZ"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "lora_model.to(device)\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8X8TpzwDBTH"
      },
      "outputs": [],
      "source": [
        "outputs = lora_model(**batch)\n",
        "print(outputs.loss, outputs.logits.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adafactor(lora_model.parameters(), lr=1e-4, relative_step=False)\n",
        "\n",
        "num_epochs = 5\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "print(num_training_steps)"
      ],
      "metadata": {
        "id": "ZvuJMSyVfDYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0x5O8_JcFrnT"
      },
      "outputs": [],
      "source": [
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "precision = evaluate.load(\"precision\")\n",
        "recall = evaluate.load(\"recall\")\n",
        "f1 = evaluate.load(\"f1\")\n",
        "\n",
        "metrics_lora = evaluate.combine([\"precision\",\"f1\",\"recall\"])\n",
        "\n",
        "mlflow.set_experiment(\"LoRA_PEFT_IMDB\")\n",
        "mlflow.pytorch.autolog()\n",
        "step = 1\n",
        "\n",
        "with mlflow.start_run(log_system_metrics=True) as run:\n",
        "  for epoch in range(num_epochs):\n",
        "    lora_model.train()\n",
        "    for batch in train_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = lora_model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        step +=1\n",
        "        mlflow.log_metric(\"train_loss\", loss.item(), step=step)\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "\n",
        "    lora_model.eval()\n",
        "    for batch in val_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = lora_model(**batch)\n",
        "\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "        metrics_lora.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "    results = metrics_lora.compute(average=\"weighted\")\n",
        "    ml_metrics = {\"eval_precision\": results[\"precision\"],\n",
        "                  \"eval_recall\": results[\"recall\"],\n",
        "                  \"eval_f1\": results[\"f1\"]}\n",
        "    mlflow.log_metrics(ml_metrics, step=epoch)\n",
        "    print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### QLoRA"
      ],
      "metadata": {
        "id": "KEM1y_tGu_Mx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sXr0NkXHqY3"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "qlora_model.to(device)\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = qlora_model(**batch)\n",
        "print(outputs.loss, outputs.logits.shape)"
      ],
      "metadata": {
        "id": "XJFfnjRA1X-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adafactor(qlora_model.parameters(), lr=1e-4, relative_step=False)\n",
        "\n",
        "num_epochs = 5\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "print(num_training_steps)"
      ],
      "metadata": {
        "id": "oMMVHqax1cQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "precision = evaluate.load(\"precision\")\n",
        "recall = evaluate.load(\"recall\")\n",
        "f1 = evaluate.load(\"f1\")\n",
        "\n",
        "metrics_qlora = evaluate.combine([\"precision\",\"f1\",\"recall\"])\n",
        "\n",
        "mlflow.set_experiment(\"QLoRA_PEFT_IMDB\")\n",
        "mlflow.pytorch.autolog()\n",
        "step = 1\n",
        "\n",
        "with mlflow.start_run(log_system_metrics=True) as run:\n",
        "  for epoch in range(num_epochs):\n",
        "    qlora_model.train()\n",
        "    for batch in train_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = qlora_model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        step +=1\n",
        "        mlflow.log_metric(\"train_loss\", loss.item(), step=step)\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "\n",
        "    qlora_model.eval()\n",
        "    for batch in val_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = qlora_model(**batch)\n",
        "\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "        metrics_qlora.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "    results = metrics_qlora.compute(average=\"weighted\")\n",
        "    ml_metrics = {\"eval_precision\": results[\"precision\"],\n",
        "                  \"eval_recall\": results[\"recall\"],\n",
        "                  \"eval_f1\": results[\"f1\"]}\n",
        "    mlflow.log_metrics(ml_metrics, step=epoch)\n",
        "    print(results)"
      ],
      "metadata": {
        "id": "yIartY651iIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Evaluation\n",
        "\n",
        "After training the model, we need to use unseen data to valuate the model capability on classificating reviews. This step is important to guarantee that the model don't just memorize the classes of the training samples. In this example, the IMDB dataset has a test group containing 25k samples of movie reviews\n",
        "\n",
        "### PEFT"
      ],
      "metadata": {
        "id": "LUCasYfopEsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "precision = evaluate.load(\"precision\")\n",
        "recall = evaluate.load(\"recall\")\n",
        "f1 = evaluate.load(\"f1\")\n",
        "\n",
        "metrics = evaluate.combine([\"precision\",\"f1\",\"recall\"])\n",
        "\n",
        "model.eval()\n",
        "for batch in test_dataloader:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=-1)\n",
        "    metrics.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "results = metrics.compute(average=\"weighted\")\n",
        "print(results)"
      ],
      "metadata": {
        "id": "oG-5BDAEnJ8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LoRA"
      ],
      "metadata": {
        "id": "kqasge2Vp1bC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "precision = evaluate.load(\"precision\")\n",
        "recall = evaluate.load(\"recall\")\n",
        "f1 = evaluate.load(\"f1\")\n",
        "\n",
        "metrics_lora = evaluate.combine([\"precision\",\"f1\",\"recall\"])\n",
        "\n",
        "lora_model.eval()\n",
        "for batch in test_dataloader:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = lora_model(**batch)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=-1)\n",
        "    metrics_lora.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "results = metrics_lora.compute(average=\"weighted\")\n",
        "print(results)"
      ],
      "metadata": {
        "id": "b_pTx3Vgp1JC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### QLoRA"
      ],
      "metadata": {
        "id": "01nES_P7p3og"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "precision = evaluate.load(\"precision\")\n",
        "recall = evaluate.load(\"recall\")\n",
        "f1 = evaluate.load(\"f1\")\n",
        "\n",
        "metrics_qlora = evaluate.combine([\"precision\",\"f1\",\"recall\"])\n",
        "\n",
        "qlora_model.eval()\n",
        "for batch in test_dataloader:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = qlora_model(**batch)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=-1)\n",
        "    metrics_qlora.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "results = metrics_qlora.compute(average=\"weighted\")\n",
        "print(results)"
      ],
      "metadata": {
        "id": "jy-fEXWYp0qR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2iULrKoPr99q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "include_colab_link": true
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}